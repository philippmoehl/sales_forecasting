{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c3e4052-b0c3-4fd0-914b-b3420acb862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import warnings\n",
    "\n",
    "import holidays\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "matplotlib.rcParams.update({'font.size': 15})\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb4ca3ff-94f3-40af-92bb-edaf0a9cf022",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = Path.cwd().parent\n",
    "DATA_PATH = BASE_PATH / \"data\"\n",
    "\n",
    "train = pd.read_csv(DATA_PATH / \"train.csv\")\n",
    "test = pd.read_csv(DATA_PATH / \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2406d58-473b-420d-836a-775439d3e99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test], axis=0)\n",
    "df['log'] = np.log(df['num_sold'])\n",
    "\n",
    "# add date\n",
    "df['date']  = pd.to_datetime(df['date'])\n",
    "df['year']  = df['date'].dt.year\n",
    "df['week']  = df['date'].dt.dayofweek\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day']   = df['date'].dt.day\n",
    "df['time_no'] = (df['date'] - dt.datetime(2017, 1, 1)) // dt.timedelta(days=1)\n",
    "df.loc[df['date'] > dt.datetime(2020, 2, 29), 'time_no'] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c86117a7-ee9d-424f-9b97-3f6397d0d7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the years and countries\n",
    "years = [2017,2018,2019,2020,2021,2022]\n",
    "countries = train.country.unique()\n",
    "\n",
    "dfs = []\n",
    "# Generate holidays for each country and year\n",
    "for year in years:\n",
    "    for country in countries:\n",
    "        for date, holiday_name in sorted(holidays.CountryHoliday(country, years=year).items()):\n",
    "            \n",
    "            df_0 = pd.DataFrame({\"date\": [date], \"country\": [\n",
    "                              country]})\n",
    "            dfs.append(df_0)\n",
    "\n",
    "# Concatenate all the DataFrames\n",
    "df_holidays = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Convert 'date' column to datetime\n",
    "df_holidays['date'] = pd.to_datetime(df_holidays['date'])\n",
    "df_holidays['tmp'] = 1\n",
    "\n",
    "#remove certain holidays since the data doesn't have \"holiday upturn\" on these holidays\n",
    "df_holidays = df_holidays[~((df_holidays['date'].dt.month.isin([2,4,5,8,10])) & (df_holidays['country'] == 'Canada'))]\n",
    "# remove New Year and Christmas Holiday because I will handle them seperately\n",
    "for country in ['Argentina', 'Canada', 'Estonia', 'Spain']:\n",
    "    for year in years:\n",
    "        df_holidays = df_holidays[~((df_holidays['date'] == pd.to_datetime(\n",
    "            f'{year}-01-01')) & (df_holidays['country'] == country))]\n",
    "df_holidays = df_holidays[~((df_holidays['date'] == pd.to_datetime(\n",
    "    '2017-01-02')) & (df_holidays['country'] == 'Spain'))]\n",
    "\n",
    "for country in ['Argentina', 'Canada', 'Estonia', 'Spain']:\n",
    "    for year in years:\n",
    "        df_holidays = df_holidays[~((df_holidays['date'] == pd.to_datetime(\n",
    "            f'{year}-12-25')) & (df_holidays['country'] == country))]\n",
    "df_holidays = df_holidays[~((df_holidays['date'] == pd.to_datetime(\n",
    "    '2022-12-26')) & (df_holidays['country'] == 'Spain'))]\n",
    "\n",
    "# Canada and Estonia has additional holiday on 26th following Christmas. I will handle them separately\n",
    "for country in ['Canada', 'Estonia']:\n",
    "    for year in years:\n",
    "        df_holidays = df_holidays[~((df_holidays['date'] == pd.to_datetime(\n",
    "            f'{year}-12-26')) & (df_holidays['country'] == country))]\n",
    "\n",
    "#Canada has additional holiday on 27, 28. I remove them and it increases cross validation\n",
    "df_holidays = df_holidays[~((df_holidays['date'] == pd.to_datetime('2020-12-28')) & (df_holidays['country'] == 'Canada'))]\n",
    "df_holidays = df_holidays[~((df_holidays['date'] == pd.to_datetime('2021-12-27')) & (df_holidays['country'] == 'Canada'))]\n",
    "df_holidays = df_holidays[~((df_holidays['date'] == pd.to_datetime('2021-12-28')) & (df_holidays['country'] == 'Canada'))]\n",
    "df_holidays = df_holidays[~((df_holidays['date'] == pd.to_datetime('2022-12-27')) & (df_holidays['country'] == 'Canada'))]\n",
    "\n",
    "#it seems that Japan doesn't celebrate on this day. I remove it and it increases cross validation\n",
    "df_holidays = df_holidays[~((df_holidays['date'] == pd.to_datetime(\n",
    "            f'2018-12-24')) & (df_holidays['country'] == 'Japan'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c4f6f5d-5698-4f79-8390-c31ce6f80001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gdp_per_capita(country, year):\n",
    "    alpha3 = {'Argentina': 'ARG', 'Canada': 'CAN',\n",
    "              'Estonia': 'EST', 'Japan': 'JPN', 'Spain': 'ESP'}\n",
    "    url = \"https://api.worldbank.org/v2/country/{0}/indicator/NY.GDP.PCAP.CD?date={1}&format=json\".format(\n",
    "        alpha3[country], year)\n",
    "    response = requests.get(url).json()\n",
    "    return response[1][0]['value']\n",
    "\n",
    "\n",
    "gdp = []\n",
    "for country in train.country.unique():\n",
    "    row = []\n",
    "    for year in range(2017, 2023):\n",
    "        row.append(get_gdp_per_capita(country, year))\n",
    "    gdp.append(row)\n",
    "\n",
    "gdp = np.array(gdp)\n",
    "gdp /= np.sum(gdp)\n",
    "\n",
    "rel_gdp_df = pd.DataFrame(gdp, index=train.country.unique(), columns=range(2017, 2023))\n",
    "df['rel_gdp'] = df.apply(lambda s: rel_gdp_df.loc[s.country, s.date.year], axis=1)\n",
    "df['log_rel_gdp'] = np.log(df['rel_gdp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "309cf7b5-5758-43ca-ab39-762d2e01ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# holiday\n",
    "holiday_diff = [np.exp(-(i - 4.5) ** 2 / 8.5) for i in range(11)]\n",
    "holidays_columns = ['holiday']\n",
    "df['holiday'] = 0\n",
    "for day_no, diff in enumerate(holiday_diff):\n",
    "    shifted = df_holidays.copy()\n",
    "    shifted['date'] = shifted['date'] + dt.timedelta(days=day_no)\n",
    "    df = pd.merge(df, shifted, on=['country', 'date'], how='left')\n",
    "    df['tmp'].fillna(0, inplace=True)\n",
    "    df['holiday'] += df['tmp'] * diff\n",
    "    df.drop(columns='tmp', inplace=True)\n",
    "# New Year's holiday\n",
    "special_date_columns = []\n",
    "for day in range(25, 32):\n",
    "    column = 'day_12_{}'.format(day)\n",
    "    df[column] = ((df['month'] == 12) & (df['day'] == day) &\n",
    "                  (df['country'] != 'Japan')).astype(float)\n",
    "    special_date_columns.append(column)\n",
    "for day in range(1, 11):\n",
    "    column = 'day_1_{}'.format(day)\n",
    "    df[column] = ((df['month'] == 1) & (df['day'] == day) & \n",
    "                  ((df['year'] == 2017) | (df['country'] != 'Japan'))).astype(float)\n",
    "    special_date_columns.append(column)\n",
    "holiday_countries = ['Estonia','Canada']\n",
    "column = 'holiday_1226'\n",
    "holiday_diff = [np.exp(-(i - 4.5) ** 2 / 8.5) for i in range(11)]\n",
    "df[column] = 0\n",
    "for day_no, diff in enumerate(holiday_diff):\n",
    "    df.loc[(df['country'].isin(holiday_countries)) & (df['month'] == 12) & (df['day'] == 26 + day_no), column] = diff\n",
    "    df.loc[(df['country'].isin(holiday_countries)) & (df['month'] ==  1) & (df['day'] == -5 + day_no), column] = diff\n",
    "\n",
    "special_date_columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8706299c-9912-4036-b1bb-5dbfce5e5218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sin wave\n",
    "year_columns = ['year_sin_1', 'year_cos_1', 'year_sin_0.5', 'year_cos_0.5']\n",
    "df['year_sin_1']   = np.sin(np.pi * df['time_no'] / 182.5)\n",
    "df['year_cos_1']   = np.cos(np.pi * df['time_no'] / 182.5)\n",
    "df['year_sin_0.5'] = np.sin(np.pi * df['time_no'] / 365.0)\n",
    "df['year_cos_0.5'] = np.cos(np.pi * df['time_no'] / 365.0)\n",
    "\n",
    "# prodcut feature.\n",
    "#I did crossvalidation and find that we only need simple sin and cos wave\n",
    "product_year_columns = []\n",
    "for product in train['product'].unique():\n",
    "    df[product] = (df['product'] == product).astype(float)\n",
    "    product_sin = '{}_sin'.format(product)\n",
    "    product_cos = '{}_cos'.format(product)\n",
    "    if product == 'Using LLMs to Train More LLMs' or product == 'Using LLMs to Win Friends and Influence People':\n",
    "        df[product_sin] = df[product] * df['year_sin_0.5']\n",
    "        df[product_cos] = df[product] * df['year_cos_0.5']\n",
    "\n",
    "        product_year_columns.append(product_sin)\n",
    "        product_year_columns.append(product_cos)\n",
    "    elif product == 'Using LLMs to Write Better' or product== 'Using LLMs to Improve Your Coding':\n",
    "        df[product_sin] = df[product] * df['year_sin_1']\n",
    "        product_year_columns.append(product_sin)    \n",
    "    else:\n",
    "        df[product_cos] = df[product] * df['year_cos_1']\n",
    "        product_year_columns.append(product_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecd48bac-3d0f-4975-901b-035ca9666ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make month flag in 2020\n",
    "featured_month_columns = []\n",
    "for month in range(3, 11):\n",
    "    column = 'month_2020_{}'.format(month)\n",
    "    df[column] = ((df['year'] == 2020) & (df['month'] == month)).astype(float)\n",
    "    featured_month_columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99a143be-a0a2-43e7-af13-e5e717a3187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# week flag\n",
    "week_columns = []\n",
    "for week in range(4, 7):\n",
    "    column = 'week_{}'.format(week)\n",
    "    df[column] = (df['week'] == week).astype(float)\n",
    "    week_columns.append(column)\n",
    "store_columns = []\n",
    "\n",
    "for store in train.store.unique()[1:]:\n",
    "    column = 'store_{}'.format(store)\n",
    "    df[column] = ((df['store'] == store)).astype(float)\n",
    "    #df[column] = ((df['store'] == store) & (df['year'] != 2020)).astype(float)\n",
    "    store_columns.append(column)\n",
    "# product\n",
    "product_columns = []\n",
    "for product in train['product'].unique()[1:]:\n",
    "    column = 'product_{}'.format(product)\n",
    "    df[column] = (df['product'] == product).astype(float)\n",
    "    product_columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab5d9309-3c4e-4a87-a227-eafdc8a2bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "# decide use columns\n",
    "use_columns = []\n",
    "use_columns.extend(special_date_columns)\n",
    "use_columns.extend(product_year_columns)\n",
    "use_columns.extend(holidays_columns)\n",
    "use_columns.extend(week_columns)\n",
    "use_columns.extend(store_columns)\n",
    "use_columns.extend(product_columns)\n",
    "use_columns.extend(featured_month_columns)\n",
    "\n",
    "\n",
    "# learning\n",
    "df_used = df.copy()\n",
    "date = dt.datetime(2021, 12, 31)\n",
    "df_used = df_used.loc[df_used['date'] <= date]\n",
    "source = df_used[use_columns]\n",
    "target = df_used['log']-df_used['log_rel_gdp']\n",
    "\n",
    "model = Pipeline([\n",
    "    ('standardize', StandardScaler()),\n",
    "    ('linear_reg', Ridge(alpha=150, tol=0.00001, max_iter=10000))\n",
    "\n",
    "])\n",
    "model.fit(source, target)\n",
    "linear_reg_model = model.named_steps['linear_reg']\n",
    "coef = pd.DataFrame(linear_reg_model.coef_, columns=['coef'])\n",
    "coef['column'] = source.columns\n",
    "coef.set_index('column', inplace=True)\n",
    "coef.loc['intercept'] = linear_reg_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dac76e0f-6620-4826-9cba-0425a5e65f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e smape  = 0.044295043764811304\n"
     ]
    }
   ],
   "source": [
    "# show results\n",
    "df['predict_log'] = model.predict(df[use_columns])+df['log_rel_gdp']\n",
    "df['predict_exp'] = np.exp(df['predict_log'])\n",
    "\n",
    "\n",
    "df['smape_log'] = 2 * (df['log'] - df['predict_log']).abs() / (df['log'] + df['predict_log'])\n",
    "\n",
    "df['smape_exp'] = 2 * (df['num_sold'] - df['predict_exp']).abs() / (df['num_sold'] + df['predict_exp'])\n",
    "\n",
    "result = df.loc[df['date'] <= date]\n",
    "print('e smape  = {}'.format(result['smape_exp'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c29f2428-57dc-4393-83d4-d5d55f93e752",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df.sort_values('id')\n",
    "result_2 = result.copy()\n",
    "result_2.loc[(result_2['year'] == 2022)&(result_2['country'] == 'Argentina'), 'predict_exp'] *= 3.372\n",
    "result_2.loc[(result_2['year'] == 2022)&(result_2['country'] == 'Spain'), 'predict_exp'] *= 1.6\n",
    "result_2.loc[(result_2['year'] == 2022)&(result_2['country'] == 'Japan'), 'predict_exp'] *= 1.394\n",
    "result_2.loc[(result_2['year'] == 2022)&(result_2['country'] == 'Estonia'), 'predict_exp'] *= 1.651\n",
    "result_2.loc[(result_2['year'] == 2022)&(result_2['country'] == 'Canada'), 'predict_exp'] *= 0.850\n",
    "result_2 = result_2.loc[result_2['date'] >= dt.datetime(2022, 1, 1), ['id', 'predict_exp']]\n",
    "\n",
    "\n",
    "#round\n",
    "result_2['predict_exp'] = np.round(result_2['predict_exp'],0)\n",
    "result_2.rename(columns={'predict_exp':'num_sold'}).to_csv('submission.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "440c17a5-a31e-4c6e-9484-ea2d37d6da73",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (178013030.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[18], line 23\u001b[0;36m\u001b[0m\n\u001b[0;31m    plt.show(\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "result = df.sort_values('id')\n",
    "result_2 = result.copy()\n",
    "result_2.loc[(result_2['year'] == 2022)&(result_2['country'] == 'Argentina'), 'predict_exp'] *= 3.372\n",
    "result_2.loc[(result_2['year'] == 2022)&(result_2['country'] == 'Spain'), 'predict_exp'] *= 1.6\n",
    "result_2.loc[(result_2['year'] == 2022)&(result_2['country'] == 'Japan'), 'predict_exp'] *= 1.394\n",
    "result_2.loc[(result_2['year'] == 2022)&(result_2['country'] == 'Estonia'), 'predict_exp'] *= 1.651\n",
    "result_2.loc[(result_2['year'] == 2022)&(result_2['country'] == 'Canada'), 'predict_exp'] *= 0.850\n",
    "\n",
    "\n",
    "# First loop over products\n",
    "for i, product in enumerate(train['product'].unique()):\n",
    "    print(product)\n",
    "    fig = plt.figure(figsize=(18, 3))\n",
    "\n",
    "    # Then loop over countries for each product\n",
    "    for country in train['country'].unique():\n",
    "        result_graph = result_2.loc[(result['country'] == country) &\n",
    "                                  (result['store'] == 'Kaggle Learn') & (result['date'] > dt.datetime(2021, 10, 31)) & (result['date'] < dt.datetime(2022, 5, 31))]\n",
    "        view = result_graph.loc[result_graph['product'] == product]\n",
    "        plt.plot(view['date'], view['predict_exp'],label=country)\n",
    "    plt.legend()\n",
    "    plt\n",
    "    plt.show("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95b7041-1306-4cd0-a8ed-a020d1a64703",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
